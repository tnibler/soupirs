{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ipywidgets import widgets\n",
    "from ipyfilechooser import FileChooser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: don't use column names, only indices and skip rows that are all Nan or string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/CPET ambu anonyme/153620_28_4_2021_15_7excelrawdata.xlsx', skiprows=2)\n",
    "# df = pd.read_excel('./data/CPET ambu anonyme/318092_29_1_2021_14_57excelrawdata.xlsx', header=None)\n",
    "# (~df.isna()).any(axis=1).idxmax()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TestFile:\n",
    "    excel_path: Path\n",
    "    raw_path: Path\n",
    "    label: str\n",
    "\n",
    "def list_test_file_pairs(data_dir: Path) -> list[TestFile]:\n",
    "    # Todo update this logic for files with name as prefix\n",
    "    files: list[TestFile] = []\n",
    "    for xls in data_dir.glob('*.xlsx'):\n",
    "        prefix = xls.name.split('_')[0]\n",
    "        log_match = list(data_dir.glob(f'{prefix}*raw.log'))\n",
    "        if len(log_match) == 0:\n",
    "            print(f'No matching raw log for Excel file {xls}')\n",
    "        elif len(log_match) > 1:\n",
    "            print(f'More then 1 matching raw log for Excel file {xls}?')\n",
    "        else:\n",
    "            files.append(TestFile(xls, log_match[0], label=prefix))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframes(file: TestFile):\n",
    "    # some xls files have empty rows at the top, so read once to know how many to skip\n",
    "    df_cycles = pd.read_excel(file.excel_path, header=None)\n",
    "    n_empty_rows = (~df.isna()).any(axis=1).idxmax()\n",
    "    df_cycles = pd.read_excel(file.excel_path, skiprows=n_empty_rows)\n",
    "    assert df_cycles['Unnamed: 0'][1] == 'Unité'\n",
    "    assert df_cycles['Unnamed: 0'][2] == 'Théor.'\n",
    "    # df_cycles = df_cycles.drop('Unnamed: 0', axis=1)\n",
    "    df_cycles = df_cycles.drop('Temps', axis=1)\n",
    "    df_cycles = df_cycles.drop([0, 1, 2])\n",
    "    keep_columns = {'Unnamed: 0', 'Vol.Cour.', 'VIn', 'tIn', 'VEx', 'tEx', 'ttot'}\n",
    "    df_cycles = df_cycles.drop([col for col in df_cycles.columns if col not in keep_columns], axis=1)\n",
    "    df_cycles = df_cycles.rename(columns={\n",
    "        'Unnamed: 0': 'phase',\n",
    "        'Vol.Cour.': 'vol_instant',\n",
    "        'VIn': 'vol_in',\n",
    "        'VEx': 'vol_ex',\n",
    "        'tIn': 't_in',\n",
    "        'tEx': 't_ex',\n",
    "        'ttot': 'duration'\n",
    "    })\n",
    "    df_cycles['phase'] = df_cycles['phase'].replace('Repos', 'rest')\n",
    "    df_cycles['phase'] = df_cycles['phase'].replace('Charge', 'load')\n",
    "    df_cycles['phase'] = df_cycles['phase'].replace('Récupération', 'recovery')\n",
    "    df_cycles['phase'] = df_cycles['phase'].ffill()\n",
    "\n",
    "    # drop rows with missing/'-' values at the end\n",
    "    df_cycles = df_cycles.drop(df_cycles[df_cycles['vol_ex'] == '-'].index)\n",
    "    float_cols = ['vol_instant', 'vol_in', 't_in', 'vol_ex', 't_ex', 'duration']\n",
    "    for col in float_cols:\n",
    "        df_cycles[col] = df_cycles[col].astype(float)\n",
    "    df_cycles = df_cycles.reset_index(drop=True)\n",
    "\n",
    "    df_raw = pd.read_csv(file.raw_path, delimiter='\\t', names=['t', 'flow', 'fo2', 'fco2'])\n",
    "    df_raw.set_index('t')\n",
    "    return df_cycles, df_raw\n",
    "\n",
    "def analyze(file: TestFile):\n",
    "    df_raw, df_cycles = load_dataframes(file)\n",
    "    \n",
    "    sampling_freq_hz = 1 / (df_raw['t'][:-1] - df_raw['t'].shift(1)[1:]).mean()\n",
    "    filter_freq_hz = 2*1e-6\n",
    "    df_raw['instant_vol_raw'] = cumulative_trapezoid(y=df_raw['flow'], x=df_raw['t'], initial=0) \n",
    "    sos = signal.butter(4, Wn=filter_freq_hz * sampling_freq_hz, btype='highpass', output='sos')\n",
    "    flow_filtered = signal.sosfilt(sos, df_raw['flow'])\n",
    "    df_raw['instant_vol'] = cumulative_trapezoid(y=flow_filtered, x=df_raw['t'], initial=0) \n",
    "    print(f'Sum over all instantaneous volume: {df_raw.instant_vol.sum()}')\n",
    "\n",
    "    peaks, peakprops  = signal.find_peaks(df_raw['instant_vol'], prominence=0.12)\n",
    "    valls, vallprops = signal.find_peaks(-df_raw['instant_vol'], prominence=0.12)\n",
    "    print(f'Found {len(peaks)} peaks, {len(valls)} valleys')\n",
    "    # index of first peak that comes after first valley\n",
    "    first_peak_idx = np.argwhere(peaks > valls[0]).min()\n",
    "    # index of last peak that comes before last valley\n",
    "    last_peak_idx = np.argwhere(valls[-1] < peaks).min()\n",
    "    first_peak_idx, last_peak_idx\n",
    "    print(f'Dropping first {first_peak_idx} and last {len(peaks) - last_peak_idx} peaks')\n",
    "    peaks = peaks[first_peak_idx:last_peak_idx]\n",
    "\n",
    "    #   p   p   p   n peaks\n",
    "    #  / \\_/ \\_/ \\\n",
    "    # v   v   v   v n+1 valleys\n",
    "\n",
    "    # That makes n complete cycles\n",
    "\n",
    "    assert len(peaks) == len(valls) - 1\n",
    "    iv = df_raw['instant_vol']\n",
    "    vins = iv[peaks].array - iv[valls[:-1]].array\n",
    "    vexs = iv[peaks].array - iv[valls[1:]].array\n",
    "    print(f'{len(peaks)} cycles')\n",
    "\n",
    "    pad_cycle_data = len(vins) - len(df_cycles['vol_in'])\n",
    "    cyc_vol_in_padded = np.pad(df_cycles['vol_in'].array, (pad_cycle_data, 0))\n",
    "    corr = np.correlate(cyc_vol_in_padded, vins, 'full')\n",
    "    shift = corr.argmax() - (len(vins) - 1)\n",
    "    drop_highres_cycles_front = pad_cycle_data - shift\n",
    "    drop_highres_cycles_back = shift \n",
    "    vins_trimmed = vins[drop_highres_cycles_front:len(vins) - drop_highres_cycles_back]\n",
    "    peaks_trimmed = peaks[drop_highres_cycles_front:len(peaks) - drop_highres_cycles_back]\n",
    "    valls_trimmed = valls[drop_highres_cycles_front:len(valls) - drop_highres_cycles_back]\n",
    "    peaks_trimmed.shape, vins.shape, vins_trimmed.shape, valls_trimmed.shape\n",
    "    df_cycles['highres_t_start'] = df_raw['t'][valls_trimmed[:-1]].values\n",
    "    df_cycles['highres_t_max'] = df_raw['t'][peaks_trimmed].values\n",
    "    df_cycles['highres_t_end'] = df_raw['t'][valls_trimmed[1:]].values\n",
    "    df_cycles['highres_duration'] = df_cycles['highres_t_end'] - df_cycles['highres_t_start']\n",
    "    return df_cycles, df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_analyze_clicked(file: TestFile):\n",
    "    global df_cycles\n",
    "    global df_raw\n",
    "    df_cycles, df_raw = analyze(file)\n",
    "\n",
    "def on_dir_chosen(chooser):\n",
    "    data_dir = Path(chooser.value)\n",
    "    files = list_test_file_pairs(data_dir)\n",
    "    select = widgets.Select(options=[(file.label, file) for file in files], layout={'height': '300px'})\n",
    "    display(select)\n",
    "    button = widgets.Button(description='Analyze')\n",
    "    button.on_click(lambda button: on_analyze_clicked(select.value))\n",
    "    display(button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser()\n",
    "fc.show_only_dirs=True\n",
    "fc.default_path = '/home/thomas/p/soupirs/data/CPET ambu anonyme'\n",
    "fc.title = 'Pick folder with raw csv and excel files'\n",
    "fc.register_callback(on_dir_chosen)\n",
    "fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Edge cases*\n",
    "|file|time|\n",
    "|-|-|\n",
    "|ambu 1091879|836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cycles.loc[(df_cycles['highres_duration'] - df_cycles['duration']).abs() > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df_cycles, y=['duration', df_cycles['highres_t_end'] - df_cycles['highres_t_start']], hover_data=['highres_t_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['vol_cycle_start'] = pd.Series(dtype=float)\n",
    "df_raw.loc[df_raw['t'].isin(df_cycles['highres_t_start'].values), 'vol_cycle_start'] = df_raw[df_raw['t'].isin(df_cycles['highres_t_start'].values)]['instant_vol']\n",
    "fig = px.line(df_raw, x='t', y='instant_vol')\n",
    "fig = fig.add_scatter(x=df_raw.t, y=df_raw['vol_cycle_start'], mode='lines+markers')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlated = pd.DataFrame()\n",
    "df_correlated['vol_in_highres'] = vins_trimmed\n",
    "df_correlated['vol_in_cycles'] = df_cycles['vol_in']\n",
    "px.scatter(df_correlated, df_correlated.index, ['vol_in_highres', 'vol_in_cycles'], title='Vol Insp cycles/highres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vexs_trimmed = vexs[drop_highres_cycles_front:len(vexs)-drop_highres_cycles_back]\n",
    "cyc_vol_ex = df_cycles['vol_ex']\n",
    "df_correlated['vol_ex_highres'] = vexs_trimmed\n",
    "df_correlated['vol_ex_cycles'] = df_cycles['vol_ex']\n",
    "px.scatter(df_correlated, df_correlated.index, ['vol_ex_highres', 'vol_ex_cycles'], title='Vol Exp cycles/highres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df_raw, x='t', y=['instant_vol_raw', 'instant_vol', 'flow'])\n",
    "# px.scatter(df_raw, x='t', y=peaks)\n",
    "# px.line(df_raw, x='t', y=['flow', 'flow_ma', 'filtered', 'instant_vol'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
