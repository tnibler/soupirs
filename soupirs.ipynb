{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ipywidgets import widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: don't use column names, only indices and skip rows that are all Nan or string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cycles.count().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/CPET ambu anonyme/153620_28_4_2021_15_7excelrawdata.xlsx', skiprows=2)\n",
    "# df = pd.read_excel('./data/CPET ambu anonyme/318092_29_1_2021_14_57excelrawdata.xlsx', header=None)\n",
    "# Some cleanup is required because for some excel files the headers are messed up and inconsistent\n",
    "keep_cols = [0, 8, 15, 16, 17, 18, 35]\n",
    "keep_col_names = ['phase', 'vol_instant', 'vol_in', 't_in', 'vol_ex', 't_ex', 'duration']\n",
    "df.drop([df.columns[col] for col in range(len(df.columns)) if col not in keep_cols], axis=1, inplace=True)\n",
    "df.columns = keep_col_names\n",
    "# for all columns except col 0, cast to float and set string data in headers to NaN\n",
    "for col in df.columns[1:]:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "first_valid_row = 0\n",
    "while df.loc[first_valid_row, df.columns[1:]].isna().any():\n",
    "    first_valid_row += 1\n",
    "df.drop(range(first_valid_row), inplace=True)\n",
    "df\n",
    "# first_valid_row, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TestFile:\n",
    "    excel_path: Path\n",
    "    raw_path: Path\n",
    "    label: str\n",
    "\n",
    "def list_test_file_pairs(data_dir: Path) -> list[TestFile]:\n",
    "    # Todo update this logic for files with name as prefix\n",
    "    files: list[TestFile] = []\n",
    "    for xls in data_dir.glob('*.xlsx'):\n",
    "        prefix = xls.name.split('_')[0]\n",
    "        log_match = list(data_dir.glob(f'{prefix}*raw.log'))\n",
    "        if len(log_match) == 0:\n",
    "            print(f'No matching raw log for Excel file {xls}')\n",
    "        elif len(log_match) > 1:\n",
    "            print(f'More then 1 matching raw log for Excel file {xls}?')\n",
    "        else:\n",
    "            files.append(TestFile(xls, log_match[0], label=prefix))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframes(file: TestFile):\n",
    "    # some xls files have empty rows at the top, so read once to know how many to skip\n",
    "    df_cycles = pd.read_excel(file.excel_path, header=None)\n",
    "\n",
    "    keep_cols = [0, 8, 15, 16, 17, 18, 35]\n",
    "    keep_col_names = ['phase', 'vol_instant', 'vol_in', 't_in', 'vol_ex', 't_ex', 'duration']\n",
    "    assert len(keep_cols) == len(keep_col_names)\n",
    "    # drop all columns except indices in keep_cols\n",
    "    df_cycles.drop([df_cycles.columns[col] for col in range(len(df_cycles.columns)) if col not in keep_cols], axis=1, inplace=True)\n",
    "    df_cycles.columns = keep_col_names\n",
    "    # for all columns except col 0, cast to float and set string data in headers to NaN\n",
    "    for col in df_cycles.columns[1:]:\n",
    "        df_cycles[col] = pd.to_numeric(df_cycles[col], errors='coerce')\n",
    "    first_valid_row = 0\n",
    "    while df_cycles.loc[first_valid_row, df_cycles.columns[1:]].isna().any():\n",
    "        first_valid_row += 1\n",
    "    last_valid_row = df_cycles.count().max()\n",
    "    print(f'Dropping {first_valid_row - 1} first rows')\n",
    "    df_cycles.drop(range(first_valid_row), inplace=True)\n",
    "    n_rows = len(df_cycles)\n",
    "    invalid_rows_at_end = 0\n",
    "    # print(df_cycles.loc[n_rows - 1, df_cycles.columns[1:]])\n",
    "    while df_cycles.loc[n_rows - invalid_rows_at_end - 1, df_cycles.columns[1:]].isna().any():\n",
    "        invalid_rows_at_end += 1\n",
    "    print(f'Dropping {invalid_rows_at_end} last rows of {n_rows}')\n",
    "    if invalid_rows_at_end:\n",
    "        df_cycles.drop(range(n_rows - invalid_rows_at_end, n_rows), inplace=True)\n",
    "    # n_rows = len(df_cycles)\n",
    "    # print(df_cycles.loc[n_rows - 1, df_cycles.columns[1:]])\n",
    "\n",
    "    df_cycles['phase'] = df_cycles['phase'].replace('Repos', 'rest')\n",
    "    df_cycles['phase'] = df_cycles['phase'].replace('Charge', 'load')\n",
    "    df_cycles['phase'] = df_cycles['phase'].replace('Récupération', 'recovery')\n",
    "    df_cycles['phase'] = df_cycles['phase'].ffill()\n",
    "\n",
    "    float_cols = ['vol_instant', 'vol_in', 't_in', 'vol_ex', 't_ex', 'duration']\n",
    "    df_cycles.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_raw = pd.read_csv(file.raw_path, delimiter='\\t', names=['t', 'flow', 'fo2', 'fco2'])\n",
    "    # df_raw.set_index('t', inplace=True)\n",
    "    return df_cycles, df_raw\n",
    "\n",
    "def analyze(df_cycles, df_raw):\n",
    "    sampling_freq_hz = 1 / (df_raw['t'][:-1] - df_raw['t'].shift(1)[1:]).mean()\n",
    "    filter_freq_hz = 2*1e-6\n",
    "    df_raw['instant_vol_raw'] = cumulative_trapezoid(y=df_raw['flow'], x=df_raw['t'], initial=0) \n",
    "    sos = signal.butter(4, Wn=filter_freq_hz * sampling_freq_hz, btype='highpass', output='sos')\n",
    "    flow_filtered = signal.sosfilt(sos, df_raw['flow'])\n",
    "    df_raw['instant_vol'] = cumulative_trapezoid(y=flow_filtered, x=df_raw['t'], initial=0) \n",
    "    print(f'Sum over all instantaneous volume: {df_raw.instant_vol.sum()}')\n",
    "\n",
    "    MIN_PROMINENCE = 0.25\n",
    "    peaks, peakprops  = signal.find_peaks(df_raw['instant_vol'], prominence=MIN_PROMINENCE)\n",
    "    valls, vallprops = signal.find_peaks(-df_raw['instant_vol'], prominence=MIN_PROMINENCE)\n",
    "    print(f'Found {len(peaks)} peaks, {len(valls)} valleys')\n",
    "    # index of first peak that comes after first valley\n",
    "    first_peak_idx = np.argwhere(peaks > valls[0]).min()\n",
    "    if not (valls[-1] > peaks).all(): # there is a peak after the last valley\n",
    "        # index of last peak that comes before last valley\n",
    "        last_peak_idx = np.argwhere(valls[-1] < peaks).min()\n",
    "    else:\n",
    "        last_peak_idx = len(peaks - 1)\n",
    "    print(f'Dropping first {first_peak_idx} and last {len(peaks) - last_peak_idx} peaks')\n",
    "    peaks = peaks[first_peak_idx:last_peak_idx]\n",
    "\n",
    "    #   p   p   p   n peaks\n",
    "    #  / \\_/ \\_/ \\\n",
    "    # v   v   v   v n+1 valleys\n",
    "\n",
    "    # That makes n complete cycles\n",
    "\n",
    "    assert len(peaks) == len(valls) - 1\n",
    "    iv = df_raw['instant_vol']\n",
    "    vins = iv[peaks].array - iv[valls[:-1]].array\n",
    "    vexs = iv[peaks].array - iv[valls[1:]].array\n",
    "    print(f'Found {len(peaks)} complete cycles')\n",
    "\n",
    "    pad_cycle_data = len(vins) - len(df_cycles['vol_in'])\n",
    "    cyc_vol_in_padded = np.pad(df_cycles['vol_in'].array, (pad_cycle_data, 0))\n",
    "    corr = np.correlate(cyc_vol_in_padded, vins, 'full')\n",
    "    # plt.bar(range(len(corr)), corr)\n",
    "    # return\n",
    "    shift = corr.argmax() - (len(vins) - 1)\n",
    "    assert shift >= 0\n",
    "    drop_highres_cycles_front = pad_cycle_data - shift\n",
    "    drop_highres_cycles_back = shift \n",
    "    vins_trimmed = vins[drop_highres_cycles_front:len(vins) - drop_highres_cycles_back]\n",
    "    peaks_trimmed = peaks[drop_highres_cycles_front:len(peaks) - drop_highres_cycles_back]\n",
    "    valls_trimmed = valls[drop_highres_cycles_front:len(valls) - drop_highres_cycles_back]\n",
    "    print(len(peaks_trimmed), len(valls_trimmed), len(df_cycles))\n",
    "    assert len(peaks_trimmed) == len(df_cycles)\n",
    "    assert len(valls_trimmed) == len(df_cycles) + 1\n",
    "    df_cycles['highres_t_start'] = df_raw['t'][valls_trimmed[:-1]].values\n",
    "    df_cycles['highres_t_max'] = df_raw['t'][peaks_trimmed].values\n",
    "    df_cycles['highres_t_end'] = df_raw['t'][valls_trimmed[1:]].values\n",
    "    df_cycles['highres_duration'] = df_cycles['highres_t_end'] - df_cycles['highres_t_start']\n",
    "    # df_raw.set_index('t', inplace=True)\n",
    "    return df_cycles, df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(range(len(corr)), corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_analyze_clicked(file: TestFile):\n",
    "    global df_cycles\n",
    "    global df_raw\n",
    "    df_cycles, df_raw = load_dataframes(file)\n",
    "    df_cycles, df_raw = analyze(df_cycles, df_raw)\n",
    "    fig = px.line(df_cycles, y=['duration', df_cycles['highres_t_end'] - df_cycles['highres_t_start']], hover_data=['highres_t_start'])\n",
    "    fig.show()\n",
    "\n",
    "def on_dir_chosen(chooser):\n",
    "    data_dir = Path(chooser.value)\n",
    "    files = list_test_file_pairs(data_dir)\n",
    "    select = widgets.Select(options=[(file.label, file) for file in files], layout={'height': '300px'})\n",
    "    display(select)\n",
    "    button = widgets.Button(description='Analyze')\n",
    "    button.on_click(lambda button: on_analyze_clicked(select.value))\n",
    "    display(button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser()\n",
    "fc.show_only_dirs=True\n",
    "fc.default_path = '/home/thomas/p/soupirs/data/CPET ambu anonyme'\n",
    "fc.title = 'Pick folder with raw csv and excel files'\n",
    "fc.register_callback(on_dir_chosen)\n",
    "fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Edge cases*\n",
    "|file|time|\n",
    "|-|-|\n",
    "|ambu 1091879|836\n",
    "\n",
    "312525 is fucked\n",
    "\n",
    "264992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = df_cycles.count().max()\n",
    "invalid_rows_at_end = 0\n",
    "while df_cycles.loc[n_rows - invalid_rows_at_end - 1, df_cycles.columns[1:]].isna().any():\n",
    "    invalid_rows_at_end += 1\n",
    "invalid_rows_at_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cycles.loc[(df_cycles['highres_duration'] - df_cycles['duration']).abs() > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df_cycles, y=['duration', df_cycles['highres_t_end'] - df_cycles['highres_t_start']], hover_data=['highres_t_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['vol_cycle_start'] = pd.Series(dtype=float)\n",
    "df_raw.loc[df_raw['t'].isin(df_cycles['highres_t_start'].values), 'vol_cycle_start'] = df_raw[df_raw['t'].isin(df_cycles['highres_t_start'].values)]['instant_vol']\n",
    "fig = px.line(df_raw, x='t', y='instant_vol')\n",
    "fig = fig.add_scatter(x=df_raw.t, y=df_raw['vol_cycle_start'], mode='lines+markers')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlated = pd.DataFrame()\n",
    "df_correlated['vol_in_highres'] = vins_trimmed\n",
    "df_correlated['vol_in_cycles'] = df_cycles['vol_in']\n",
    "px.scatter(df_correlated, df_correlated.index, ['vol_in_highres', 'vol_in_cycles'], title='Vol Insp cycles/highres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vexs_trimmed = vexs[drop_highres_cycles_front:len(vexs)-drop_highres_cycles_back]\n",
    "cyc_vol_ex = df_cycles['vol_ex']\n",
    "df_correlated['vol_ex_highres'] = vexs_trimmed\n",
    "df_correlated['vol_ex_cycles'] = df_cycles['vol_ex']\n",
    "px.scatter(df_correlated, df_correlated.index, ['vol_ex_highres', 'vol_ex_cycles'], title='Vol Exp cycles/highres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df_raw, x='t', y=['instant_vol_raw', 'instant_vol', 'flow'])\n",
    "# px.scatter(df_raw, x='t', y=peaks)\n",
    "# px.line(df_raw, x='t', y=['flow', 'flow_ma', 'filtered', 'instant_vol'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
